{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      5\u001b[0m image1 \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m image2 \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "image1 = Image.open(\"path/to/image\")\n",
    "image2 = Image.open(\"path/to/image\")\n",
    "# Note: images have to be of equal size\n",
    "\n",
    "# Transform the images to tensors then flatten them to 1D tensors\n",
    "image1_tensor = transforms.ToTensor()(image1).reshape(1, -1).squeeze()\n",
    "image2_tensor = transforms.ToTensor()(image2).reshape(1, -1).squeeze()\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0) # dim=0 -> dimension where cosine similarity is computed\n",
    "value = float(cos(image1_tensor, image2_tensor)) # a value of 1 indicates strong similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: load all the images from the dataset (assume that all images are resized to shape=(256, 256))\n",
    "# Step 2: figure out a way to loop through all the images and compare every pair of images\n",
    "# Step 3: calculate the cosine similarity and store the picture pair ID and the similarity\n",
    "# Step 4: print out two images and sort by the similarities -- then plot the similarities\n",
    "\n",
    "# Note: do you need to normalize if you are calculating cosine similarity\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 123\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24249 files belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Importing the dataset into the model\n",
    "    # Image batch: (64, 256, 256, 3)\n",
    "    # Labels batch: (64, 10)\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"data/concatenated_datasets\",\n",
    "        seed=SEED,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode=None,\n",
    "    )\n",
    "\n",
    "    normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "    dataset = dataset.map(lambda x: (normalization_layer(x)))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "image_dataset = load_data()\n",
    "unbatched_image_dataset = image_dataset.unbatch()\n",
    "numpy_image_dataset = np.fromiter(unbatched_image_dataset.as_numpy_iterator(), dtype=np.dtype((\"float32\", (256, 256, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<_UnbatchDataset element_spec=(TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(10,), dtype=tf.float32, name=None))>\n",
      "24249\n"
     ]
    }
   ],
   "source": [
    "print(numpy_image_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !python --version\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# def background(f):\n",
    "#     def wrapped(*args, **kwargs):\n",
    "    #     return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "    # return wrapped\n",
    "\n",
    "# @background\n",
    "# def getImage(image_path):\n",
    "    # image_loaded = tf.keras.utils.load_img(image_path) \n",
    "    # image_loaded = tf.image.resize(images=image_loaded, size=(256, 256)) \n",
    "    # return image_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fetchImageFromPath(path):\n",
    "#     image_loaded = tf.keras.utils.load_img(path) \n",
    "#     image_loaded = tf.image.resize(images=image_loaded, size=(256, 256)) \n",
    "#     return image_loaded\n",
    "\n",
    "# def getCosineSimilarityFromImages(image_dataset, image_paths, i):\n",
    "#     for j in range(i, len(image_dataset)):\n",
    "#         tensor_i = torch.from_numpy(image_dataset[i]).reshape(1, -1).squeeze() \n",
    "#         tensor_j = torch.from_numpy(image_dataset[j]).reshape(1, -1).squeeze() \n",
    "#         cos_similarity = float(torch.nn.CosineSimilarity(dim=0)(tensor_i, tensor_j))\n",
    "#         print(str(cos_similarity) + \",\" + image_paths[i] + \",\" + image_paths[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED IMPORTING IMAGES\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'similarityHelpers' has no attribute 'CosineSimilarityCalculator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m image_dataset, image_paths \u001b[38;5;241m=\u001b[39m getImageDatasetFromPaths(paths)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISHED IMPORTING IMAGES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m similarityFn \u001b[38;5;241m=\u001b[39m \u001b[43msimilarityHelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCosineSimilarityCalculator\u001b[49m(image_dataset\u001b[38;5;241m=\u001b[39mimage_dataset, image_paths\u001b[38;5;241m=\u001b[39mimage_paths)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mMAX_WORKERS) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mmap(similarityFn\u001b[38;5;241m.\u001b[39mgetCosineSimilarityFromImages, paths):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'similarityHelpers' has no attribute 'CosineSimilarityCalculator'"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import similarityHelpers\n",
    "\n",
    "MAX_WORKERS = 4\n",
    "def getImageDatasetFromPaths(paths):\n",
    "    image_dataset = []\n",
    "    image_paths = []\n",
    "    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        for path in executor.map(similarityHelpers.fetchImageFromPath, paths):\n",
    "            image_dataset.append(path)\n",
    "            image_paths.append(path)\n",
    "\n",
    "    return np.array(image_dataset), np.array(image_paths)\n",
    "\n",
    "with open(\"paths.txt\", \"r\") as file:\n",
    "    paths = file.readlines()\n",
    "    paths = [i.rstrip() for i in paths]\n",
    "\n",
    "    image_dataset, image_paths = getImageDatasetFromPaths(paths)\n",
    "    print(\"FINISHED IMPORTING IMAGES\")\n",
    "    similarityFn = similarityHelpers.CosineSimilarityCalculator(image_dataset=image_dataset, image_paths=image_paths)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        for i in executor.map(similarityFn.getCosineSimilarityFromImages, paths):\n",
    "            pass\n",
    "    \n",
    "    print(\"FINISHED CALCULATING COSINE SIMLIARITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'addOne' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'addOne' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'addOne' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m pool \u001b[38;5;241m=\u001b[39m Pool()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddOne\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m##When iterated over produces [2, 3, 4]\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def addOne (x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.map(addOne, range(1, 4)) ##When iterated over produces [2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# def myfunc(id):\n",
    "#     if id % 2 == 0:\n",
    "#         return id, id\n",
    "#     else:\n",
    "#         return id, id ** 2\n",
    "if __name__ == '__main__':\n",
    "    id_array = [*range(5)]\n",
    "    result = []\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        for r in executor.map(time.sleep, id_array):\n",
    "            result.append(r)\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "id_array = [*range(5)]\n",
    "\n",
    "result = []\n",
    "for id in id_array:\n",
    "    result.append(time.sleep(id))\n",
    "    # if id % 2 == 0:\n",
    "    #     result.append((id, id))\n",
    "    # else:\n",
    "    #     result.append((id, id ** 2))\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "return arrays must be of ArrayType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/astronaut/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\nTypeError: return arrays must be of ArrayType\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 12\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m res_list1 \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]\n\u001b[1;32m     15\u001b[0m res_list2 \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/code/agrobot/grapeLD/.conda/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTypeError\u001b[0m: return arrays must be of ArrayType"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args1 = [1, 2, 3, 4]  \n",
    "    args2 = [5, 6, 7, 8]\n",
    "        \n",
    "    \n",
    "    res = []\n",
    "    with Pool(processes=4) as pool:\n",
    "        res = pool.starmap(np.sqrt, zip(args1,args2))\n",
    "\n",
    "    res_list1 = [r[0] for r in res]\n",
    "    res_list2 = [r[1] for r in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
